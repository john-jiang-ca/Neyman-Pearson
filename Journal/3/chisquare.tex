% Chi-Square Case
\subsection{MROC Surface under Chi-Square Hypotheses}
\noindent\textbf{Example:}

Assume $M+1$ hypotheses  given as:
\begin{equation}
  \label{equ: Chisquare Hypothesis}
  \begin{split}
    H_0:\;\;\;\;\;\;\;\;&\frac{X}{\sigma_0^2} \sim \mathcal{X}^2(2N)\\
    H_i:\;\;\;\;\;\;\;\;&\frac{X}{\sigma_i^2} \sim \mathcal{X}^2(2N)\;\;\;\;i=1, 2, \cdots, M
  \end{split}
\end{equation}
where $\mathcal{X}^2(2N)$ is the Chi-square distribution with  $2N$ degree freedom($N$ is an integer, $\sigma_0^2 < \sigma_1^2, ..., \sigma_M^2$ and $\sigma_i^2 \neq \sigma_j^2$ if $i \neq j$). By a random variable transformation space \cite{mark2011probability}, we can get the PDFs for the hypotheses:

\def \CHISQU[#1]{\frac{1}{#1 2^N\Gamma(N)}\left(\frac{x}{#1}\right)^{N-1}\exp\left(-\frac{x}{2#1}\right)\\}
\begin{equation}
  \label{equ: Chisquare Distribution}
  \begin{split}
    H_0:\;\;\;\;\;\;\;\;&f_0(x) = \CHISQU[\sigma_0^2]\\
    H_i:\;\;\;\;\;\;\;\;&f_i(x) = \CHISQU[\sigma_i^2]
  \end{split}
\end{equation}

In the following, we will prove that in this example the region achieved by ENP test with $\mathbf{k}$ degenerates to a curve.

Consider
 $ g(x) = \frac{\sum_{i=1}^{M}k_if_i(x)}{f_0(x)} \;\;\;\;k_i \geq 0$. 
Substituting $f_i(x) (i=1, ..., M)$ from \eqref{equ: Chisquare Distribution} into $g(x)$, we get:

\begin{equation}
  \label{equ: decision rule chi 1}
g(x) = \sum_{i=1}^{M}k_i'\exp{(\frac{1}{2\sigma_0^2} - \frac{1}{2\sigma_i^2})x} 
\end{equation}
where $k_i' = k_i(\frac{\sigma_0}{\sigma_i})^{2N}, i= 1, ..., M$. Define $p_i = \frac{1}{2\sigma_0^2} - \frac{1}{2\sigma_i^2}, i=1, ..., M$. Hence $g(x) =  \sum_{i=1}^{M}k_i'\exp{(p_ix)}$.

The parameters $k_i' (i=1, ..., M)$ are always non-negative when $k_i (i=1, ..., M)$ are such, and from 
 the condition $\sigma_0^2 \leq \sigma_i^2 (i=1, ..., M)$ we can conclude $p_i (i=1, ..., M)$ are positive. Hence $g(x)$ is a monotonically increasing function with $x$. From \textbf{Property 1}, we have that the region achieved by ENP test with $k_i (i = 1, ..., M)$ degenerates to a curve. For a specific $\mathbf{c}$, the decision rule is 
$  x \substack{\bar{H}_0 \\ \geq \\ < \\ H_0} x_0\,,$
where $x_0 = \min\{F_1^{-1}(c_1), ..., F_M^{-1}(c_M)\}$,
and the corresponding $P_d = F_0(x_0)$. 

For the case when $M=2$, $\sigma_0^2 = 1$, $\sigma_1^2 = 1.1$, $\sigma_2^2 = 1.15$ and $N=120$, the three hypotheses can be written as
\begin{equation}
  \label{2015mar29a0}
  \begin{split}
    H_0:\;\;\;\;&\frac{X}{1.00} \sim \mathcal{X}^2(240) \\ 
    H_1:\;\;\;\;&\frac{X}{1.10} \sim \mathcal{X}^2(240) \\ 
    H_2:\;\;\;\;&\frac{X}{1.15} \sim \mathcal{X}^2(240) \\ 
  \end{split}
\end{equation}
For a given $(c_1, c_2)$, the associated $P_d$ is $F_0(x_0)$ where $x_0 = \min \{F_1^{-1}(c_1),  F_2^{-1}(c_2)\}$. 
Figure \ref{pic: LJS for chisquare} presents the M-ROC surface for this example. 

